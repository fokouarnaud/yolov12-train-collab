"""
YOLOv12-Face - Entra√Ænement Sp√©cialis√©
Module d'entra√Ænement avec optimisations pour l'architecture attention-centrique
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.optim.lr_scheduler import CosineAnnealingLR, OneCycleLR
import numpy as np
import time
import logging
import wandb
import os
from pathlib import Path
from ultralytics import YOLO
from ultralytics.utils.callbacks import default_callbacks
import yaml

# Configuration logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class YOLOv12FaceTrainingEnhancer:
    """Am√©liorations sp√©cialis√©es pour l'entra√Ænement YOLOv12-Face"""
    
    def __init__(self, model, config):
        self.model = model
        self.config = config
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.training_stats = {
            'epoch_times': [],
            'lr_history': [],
            'loss_history': [],
            'attention_stats': []
        }
        
    def setup_attention_optimized_training(self):
        """Configure l'entra√Ænement optimis√© pour l'attention"""
        
        logger.info("üéØ Configuration entra√Ænement attention-centrique...")
        
        # Param√®tres sp√©ciaux pour attention
        attention_params = []
        backbone_params = []
        other_params = []
        
        for name, param in self.model.model.named_parameters():
            if 'attention' in name.lower() or 'attn' in name.lower():
                attention_params.append(param)
            elif 'backbone' in name.lower():
                backbone_params.append(param)
            else:
                other_params.append(param)
        
        # Optimiseur avec learning rates diff√©renci√©s
        param_groups = [
            {'params': attention_params, 'lr': self.config['hyperparameters']['lr0'] * 0.5, 'name': 'attention'},
            {'params': backbone_params, 'lr': self.config['hyperparameters']['lr0'] * 0.8, 'name': 'backbone'},
            {'params': other_params, 'lr': self.config['hyperparameters']['lr0'], 'name': 'other'}
        ]
        
        logger.info(f"Attention params: {len(attention_params)}")
        logger.info(f"Backbone params: {len(backbone_params)}")
        logger.info(f"Other params: {len(other_params)}")
        
        return param_groups
    
    def create_custom_callbacks(self):
        """Cr√©e des callbacks personnalis√©s pour YOLOv12-Face"""
        
        callbacks = {}
        
        # Callback pour monitoring attention
        def on_train_batch_end(trainer):
            """Callback ex√©cut√© √† la fin de chaque batch"""
            if hasattr(trainer.model, 'attention_weights'):
                # Logger attention weights
                attention_stats = {
                    'mean_attention': float(trainer.model.attention_weights.mean()),
                    'std_attention': float(trainer.model.attention_weights.std()),
                    'max_attention': float(trainer.model.attention_weights.max())
                }
                self.training_stats['attention_stats'].append(attention_stats)
        
        # Callback pour ajustement dynamique learning rate
        def on_train_epoch_end(trainer):
            """Callback √† la fin de chaque √©poque"""
            epoch = trainer.epoch
            
            # Ajustement LR bas√© sur performance attention
            if len(self.training_stats['attention_stats']) > 0:
                recent_attention = self.training_stats['attention_stats'][-10:]  # 10 derniers batchs
                avg_attention = np.mean([s['mean_attention'] for s in recent_attention])
                
                # Si attention trop faible, r√©duire LR
                if avg_attention < 0.1:
                    for param_group in trainer.optimizer.param_groups:
                        if param_group['name'] == 'attention':
                            param_group['lr'] *= 0.9
                            logger.info(f"R√©duction LR attention: {param_group['lr']:.6f}")
        
        # Callback pour sauvegarde d'attention
        def on_model_save(trainer):
            """Callback lors de sauvegarde mod√®le"""
            # Sauvegarder statistiques attention
            stats_path = Path(trainer.save_dir) / 'attention_stats.yaml'
            with open(stats_path, 'w') as f:
                yaml.dump(self.training_stats, f)
        
        callbacks['on_train_batch_end'] = on_train_batch_end
        callbacks['on_train_epoch_end'] = on_train_epoch_end
        callbacks['on_model_save'] = on_model_save
        
        return callbacks
    
    def implement_advanced_loss_functions(self):
        """Impl√©mente des fonctions de loss avanc√©es pour visages"""
        
        class NormalizedWassersteinLoss(nn.Module):
            """NWD Loss pour petits visages"""
            def __init__(self, exp_scale=1.0):
                super().__init__()
                self.exp_scale = exp_scale
            
            def forward(self, pred_boxes, target_boxes):
                # Centres des bo√Ætes
                pred_centers = torch.stack([
                    (pred_boxes[:, 0] + pred_boxes[:, 2]) / 2,
                    (pred_boxes[:, 1] + pred_boxes[:, 3]) / 2
                ], dim=1)
                
                target_centers = torch.stack([
                    (target_boxes[:, 0] + target_boxes[:, 2]) / 2,
                    (target_boxes[:, 1] + target_boxes[:, 3]) / 2
                ], dim=1)
                
                # Dimensions
                pred_wh = torch.stack([
                    pred_boxes[:, 2] - pred_boxes[:, 0],
                    pred_boxes[:, 3] - pred_boxes[:, 1]
                ], dim=1)
                
                target_wh = torch.stack([
                    target_boxes[:, 2] - target_boxes[:, 0],
                    target_boxes[:, 3] - target_boxes[:, 1]
                ], dim=1)
                
                # Distance Wasserstein
                center_dist = torch.norm(pred_centers - target_centers, dim=1)
                wh_dist = torch.norm(pred_wh - target_wh, dim=1)
                w2_dist = center_dist + wh_dist
                
                # NWD
                nwd = torch.exp(-w2_dist / self.exp_scale)
                return 1.0 - nwd.mean()
        
        class SizeSensitiveLoss(nn.Module):
            """Loss qui donne plus d'importance aux petits visages"""
            def __init__(self, alpha=2.0):
                super().__init__()
                self.alpha = alpha
            
            def forward(self, pred_boxes, target_boxes):
                # Calculer tailles des bo√Ætes target
                target_areas = (target_boxes[:, 2] - target_boxes[:, 0]) * \
                              (target_boxes[:, 3] - target_boxes[:, 1])
                
                # Poids inversement proportionnel √† la taille
                size_weights = 1.0 / (target_areas + 1e-6)
                size_weights = torch.pow(size_weights, self.alpha)
                
                # Loss standard pond√©r√©e
                standard_loss = nn.MSELoss(reduction='none')(pred_boxes, target_boxes)
                weighted_loss = standard_loss * size_weights.unsqueeze(1)
                
                return weighted_loss.mean()
        
        return {
            'nwd_loss': NormalizedWassersteinLoss(),
            'size_sensitive_loss': SizeSensitiveLoss()
        }
    
    def setup_advanced_schedulers(self, optimizer, total_epochs):
        """Configure des schedulers avanc√©s"""
        
        schedulers = {}
        
        # Cosine Annealing avec warm restarts
        schedulers['cosine_restart'] = CosineAnnealingLR(
            optimizer, 
            T_max=total_epochs // 4,
            eta_min=self.config['hyperparameters']['lrf'] * self.config['hyperparameters']['lr0']
        )
        
        # OneCycle pour attention (plus agressif)
        schedulers['onecycle'] = OneCycleLR(
            optimizer,
            max_lr=self.config['hyperparameters']['lr0'],
            total_steps=total_epochs,
            pct_start=0.3,
            anneal_strategy='cos'
        )
        
        return schedulers
    
    def implement_attention_regularization(self):
        """Impl√©mente la r√©gularisation pour les couches d'attention"""
        
        def attention_diversity_loss(attention_weights):
            """Force la diversit√© dans les poids d'attention"""
            # Calculer entropie des poids d'attention
            attention_probs = torch.softmax(attention_weights, dim=-1)
            entropy = -torch.sum(attention_probs * torch.log(attention_probs + 1e-8), dim=-1)
            
            # Encourager entropie √©lev√©e (diversit√©)
            return -entropy.mean() * 0.01
        
        def attention_sparsity_loss(attention_weights):
            """Encourage la sparsit√© dans l'attention"""
            return torch.norm(attention_weights, p=1) * 0.001
        
        return {
            'diversity_loss': attention_diversity_loss,
            'sparsity_loss': attention_sparsity_loss
        }
    
    def create_data_loading_optimizations(self):
        """Optimisations sp√©cifiques au chargement des donn√©es"""
        
        class FaceAugmentationPipeline:
            """Pipeline d'augmentation sp√©cialis√© pour visages"""
            
            def __init__(self, config):
                self.config = config
                self.face_specific_augs = self._setup_face_augmentations()
            
            def _setup_face_augmentations(self):
                """Configure augmentations sp√©cifiques aux visages"""
                import albumentations as A
                
                return A.Compose([
                    # Augmentations couleur conservatrices
                    A.ColorJitter(
                        brightness=0.2,
                        contrast=0.2,
                        saturation=0.2,
                        hue=0.1,
                        p=0.7
                    ),
                    
                    # Flou gaussien l√©ger (simule distance)
                    A.GaussianBlur(blur_limit=(1, 3), p=0.3),
                    
                    # Bruit pour robustesse
                    A.GaussNoise(var_limit=(0, 25), p=0.3),
                    
                    # Simulation conditions difficiles
                    A.RandomBrightnessContrast(
                        brightness_limit=0.3,
                        contrast_limit=0.3,
                        p=0.5
                    ),
                    
                    # Simulation compression JPEG
                    A.ImageCompression(quality_lower=70, quality_upper=100, p=0.4),
                    
                ], bbox_params=A.BboxParams(format='yolo', label_fields=['class_labels']))
        
        return FaceAugmentationPipeline(self.config)
    
    def setup_monitoring_and_logging(self):
        """Configure monitoring avanc√© avec WandB"""
        
        if not hasattr(self, 'wandb_initialized'):
            try:
                wandb.init(
                    project="yolov12-face-advanced",
                    name=f"yolov12{self.config['model']['size']}_attention",
                    config=self.config,
                    tags=[
                        "yolov12",
                        "face-detection", 
                        "attention-centric",
                        f"model-{self.config['model']['size']}"
                    ]
                )
                self.wandb_initialized = True
                logger.info("‚úÖ WandB initialis√©")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è WandB non disponible: {e}")
                self.wandb_initialized = False
        
        # M√©triques personnalis√©es √† logger
        custom_metrics = {
            'attention_diversity': 0.0,
            'attention_sparsity': 0.0,
            'small_face_ap': 0.0,
            'medium_face_ap': 0.0,
            'large_face_ap': 0.0,
            'occlusion_robustness': 0.0,
            'inference_speed_ms': 0.0
        }
        
        return custom_metrics
    
    def implement_curriculum_learning(self):
        """Impl√©mente l'apprentissage par curriculum pour YOLOv12-Face"""
        
        class FaceCurriculumScheduler:
            """Scheduler de curriculum sp√©cialis√© pour visages"""
            
            def __init__(self, total_epochs):
                self.total_epochs = total_epochs
                self.current_epoch = 0
                
                # Phases du curriculum
                self.phases = {
                    'easy': (0, total_epochs // 3),           # Gros visages d'abord
                    'medium': (total_epochs // 3, 2 * total_epochs // 3),  # Visages moyens
                    'hard': (2 * total_epochs // 3, total_epochs)  # Petits visages et occlud√©s
                }
            
            def get_current_difficulty(self, epoch):
                """Retourne la difficult√© actuelle"""
                for phase, (start, end) in self.phases.items():
                    if start <= epoch < end:
                        return phase
                return 'hard'
            
            def filter_training_data(self, data, difficulty):
                """Filtre les donn√©es selon la difficult√©"""
                if difficulty == 'easy':
                    # Garder seulement gros visages (>64px)
                    return self._filter_by_size(data, min_size=64)
                elif difficulty == 'medium':
                    # Visages moyens et gros (>32px)
                    return self._filter_by_size(data, min_size=32)
                else:
                    # Tous les visages
                    return data
            
            def _filter_by_size(self, data, min_size):
                """Filtre par taille de visage"""
                # Impl√©mentation du filtrage
                # (√† adapter selon structure des donn√©es)
                pass
        
        return FaceCurriculumScheduler(self.config['training']['epochs'])
    
    def create_ensemble_training(self):
        """Cr√©e un syst√®me d'entra√Ænement d'ensemble"""
        
        class YOLOv12FaceEnsemble:
            """Ensemble de mod√®les YOLOv12-Face"""
            
            def __init__(self, model_configs):
                self.models = []
                self.model_configs = model_configs
                
                for config in model_configs:
                    model = YOLO(f"yolov12{config['size']}.yaml")
                    self.models.append(model)
            
            def train_ensemble(self, data_config, epochs):
                """Entra√Æne l'ensemble avec strat√©gies diff√©rentes"""
                
                strategies = [
                    {'augmentation': 'conservative', 'optimizer': 'AdamW'},
                    {'augmentation': 'moderate', 'optimizer': 'Adam'},
                    {'augmentation': 'aggressive', 'optimizer': 'SGD'}
                ]
                
                for i, (model, strategy) in enumerate(zip(self.models, strategies)):
                    logger.info(f"Entra√Ænement mod√®le {i+1} avec strat√©gie: {strategy}")
                    
                    # Configuration sp√©cialis√©e pour ce mod√®le
                    model_config = self.model_configs[i].copy()
                    model_config.update(strategy)
                    
                    # Entra√Ænement
                    results = model.train(
                        data=data_config,
                        epochs=epochs,
                        **strategy
                    )
                    
                    logger.info(f"Mod√®le {i+1} termin√©: mAP={results.box.map:.3f}")
            
            def ensemble_predict(self, image_path):
                """Pr√©diction d'ensemble avec fusion des r√©sultats"""
                all_results = []
                
                for model in self.models:
                    results = model(image_path)
                    all_results.append(results)
                
                # Fusion des r√©sultats (NMS ensemble)
                return self._fuse_predictions(all_results)
            
            def _fuse_predictions(self, predictions_list):
                """Fusionne les pr√©dictions de l'ensemble"""
                # Impl√©mentation de la fusion (NMS ensemble, vote majoritaire, etc.)
                pass
        
        return YOLOv12FaceEnsemble
    

class AdvancedTrainingMetrics:
    """M√©triques avanc√©es pour l'entra√Ænement YOLOv12-Face"""
    
    def __init__(self):
        self.metrics = {}
        
    def calculate_attention_efficiency(self, model):
        """Calcule l'efficacit√© des m√©canismes d'attention"""
        total_attention_params = 0
        total_params = 0
        
        for name, param in model.named_parameters():
            total_params += param.numel()
            if 'attention' in name.lower() or 'attn' in name.lower():
                total_attention_params += param.numel()
        
        attention_ratio = total_attention_params / total_params
        return {
            'attention_param_ratio': attention_ratio,
            'attention_params': total_attention_params,
            'total_params': total_params
        }
    
    def analyze_face_size_performance(self, predictions, targets):
        """Analyse les performances par taille de visage"""
        
        size_categories = {
            'tiny': (0, 16),
            'small': (16, 32),
            'medium': (32, 64),
            'large': (64, float('inf'))
        }
        
        size_metrics = {}
        
        for category, (min_size, max_size) in size_categories.items():
            # Filtrer pr√©dictions et targets par taille
            category_preds, category_targets = self._filter_by_size(
                predictions, targets, min_size, max_size
            )
            
            # Calculer m√©triques pour cette cat√©gorie
            if len(category_targets) > 0:
                ap = self._calculate_ap(category_preds, category_targets)
                size_metrics[f'{category}_ap'] = ap
            else:
                size_metrics[f'{category}_ap'] = 0.0
        
        return size_metrics
    
    def _filter_by_size(self, predictions, targets, min_size, max_size):
        """Filtre par taille de visage"""
        # Impl√©mentation du filtrage
        pass
    
    def _calculate_ap(self, predictions, targets):
        """Calcule Average Precision"""
        # Impl√©mentation calcul AP
        pass


def main():
    """Fonction principale pour test du module d'entra√Ænement"""
    
    # Configuration de test
    config = {
        'model': {'size': 'n'},
        'hyperparameters': {
            'lr0': 0.01,
            'lrf': 0.01,
            'batch_size': 16
        },
        'training': {'epochs': 100}
    }
    
    # Cr√©er mod√®le de test
    model = YOLO('yolov12n.yaml')
    
    # Cr√©er enhancer d'entra√Ænement
    enhancer = YOLOv12FaceTrainingEnhancer(model, config)
    
    # Tester fonctionnalit√©s
    logger.info("üß™ Test des fonctionnalit√©s d'entra√Ænement avanc√©es...")
    
    # Test callbacks
    callbacks = enhancer.create_custom_callbacks()
    logger.info(f"‚úÖ Callbacks cr√©√©s: {list(callbacks.keys())}")
    
    # Test loss functions
    loss_funcs = enhancer.implement_advanced_loss_functions()
    logger.info(f"‚úÖ Loss functions: {list(loss_funcs.keys())}")
    
    # Test monitoring
    metrics = enhancer.setup_monitoring_and_logging()
    logger.info(f"‚úÖ M√©triques: {list(metrics.keys())}")
    
    logger.info("üéâ Module d'entra√Ænement avanc√© test√© avec succ√®s!")


if __name__ == "__main__":
    main()
